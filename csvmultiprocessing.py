#!/usr/bin/env python

import csv
import logging
import traceback
import sys

from multiprocessing import Process, Queue
from jinja2 import Environment, FileSystemLoader, Template

from cassandra import ConsistencyLevel
from cassandra.cluster import Cluster
from cassandra.policies import WhiteListRoundRobinPolicy
from cassandra.query import SimpleStatement, BatchStatement

log = logging.getLogger(__name__)


class CSVMultiprocessing():
  def __init__(self, config, proc_num, file, delimeter, keyspaces_meta, keyspace_column):
    self.proc_num = proc_num
    self.file = file
    self.opened_file = open(file)
    self.dataset = csv.DictReader(self.opened_file, delimiter=delimeter)
    self.keyspaces_meta = keyspaces_meta
    self.keyspace_column = keyspace_column

    self.lines_queue = Queue()
    self.batch_queue = Queue()

    self.config = config
    for config_attribute, value in config.items():
      setattr(self, config_attribute, value)
      
    self.cluster = Cluster(self.contact_points,
                      load_balancing_policy=WhiteListRoundRobinPolicy(self.contact_points),
                      max_schema_agreement_wait=self.max_schema_agreement_wait,
                      port=self.port)

    self.ps_readline = Process(target=self.get_line, args=())
    self.ps_batch = Process(target=self.execute_batch, args=())
    self.ps_processline = [ Process(target=self.process_line, args=())
                            for ps in range(self.proc_num)]
    
    self.ps_readline.start()
    self.ps_batch.start()
    for ps in self.ps_processline:
        ps.start()

    self.ps_readline.join()

    index = 0
    for ps in self.ps_processline:
      ps.join()
      print("Process {} has finished".format(index))
      index += 1

    self.ps_batch.join()
    self.opened_file.close()

  def get_line(self):
    for index, line in enumerate(self.dataset):
      self.lines_queue.put((index, line))

    for ps in range(self.proc_num):
      self.lines_queue.put("STOP")

  def process_line(self):
    """1. Get line from 'lines_queue' 2. Generate 'BatchStatement' based on
    metadata and dataset line 3. Put 'BatchStatement' to 'batch_queue'
    """
    string_formats = [ 'ascii', 'date', 'inet', 'text', 'timestamp', 'varchar' ]
    default_cl = getattr(ConsistencyLevel, self.default_consistency_level)

    for index, line in iter(self.lines_queue.get, "STOP"):
      keyspace_name = line[self.keyspace_column].lower()
      batch = BatchStatement(consistency_level=default_cl)
      columns_helper = {}
      for table_name, table_metadata in self.keyspaces_meta[keyspace_name].items():
        # Helper was created because autogenerated fields can't be mapped to a datasource column
        columns_helper = { **table_metadata['columns'], **table_metadata['columns_mapping'] }
        batch = self.add_to_batch(batch, line, keyspace_name, table_name, 
                                  table_metadata['columns'], columns_helper, string_formats)

      sys.stdout.write("Lines processed: {} \r".format(index))
      sys.stdout.flush()
      log.debug(index, batch)
      self.batch_queue.put(batch)

    self.batch_queue.put("STOP")
  
  def execute_batch(self):
    self.session = self.cluster.connect()

    for workers in range(self.proc_num):
      for batch in iter(self.batch_queue.get, "STOP"):
        self.session.execute(batch)

  def add_to_batch(self, batch, line, keyspace_name, 
                   table_name, columns_metadata, columns_helper, string_formats):
    """Generate insert statement and add them to 'BatchStatement'

    [BatchStatement] batch: group 'inserts' of a particular line  
    [OrderedDict] line: single csv line
    [String]: name of the keyspace 
    [String]: name of the table
    [Dict] columns_metadata: 'columns' dict from metadata file
    [Dict] columns_helper: columns metadata merged with csv columns mapping
    [List] string_formats: Cassandra string datatypes
    """
    insert_template = """INSERT INTO {{ keyspace_name }}.{{ table_name }}
    ({{ columns_helper.keys()|join(', ') }})
    VALUES ({% for table_column, dataset_column in columns_helper.items() -%} 
    {% if coulmns_metadata[table_column] == 'uuid'  -%}
    {{ 'uuid()' -}}
    {% elif coulmns_metadata[table_column] == 'timeuuid' -%}
    {{ 'now()' -}} 
    {% elif coulmns_metadata[table_column] in string_formats -%}
    {{ "'" -}} {{ line[dataset_column] | replace("'", "''") -}} {{ "'" -}}
    {% elif coulmns_metadata[table_column].startswith('map') -%} 
      {{ '{' -}} 
        {% for key, value in dataset_column.items() -%} 
          '{{ line[key] | replace("'", "''") }}': '{{ line[value] | replace("'", "''") -}}' 
        {%- endfor -%} 
      {{ '}' -}} 
    {% elif coulmns_metadata[table_column].startswith('list') -%} 
      {{ '[' -}} 
        {% for element in dataset_column -%} 
          '{{ line[element] | replace("'", "''") -}}'
        {%- endfor -%} 
      {{ ']' -}} 
    {% else -%} 
    {{ line[dataset_column] }} 
    {%- endif -%} 
    {{ "," if not loop.last }}
    {%- endfor -%})"""

    insert_template = Template(insert_template)
    env = Environment(trim_blocks=True, lstrip_blocks=True)
    template = env.get_template(insert_template)
    insert = template.render(keyspace_name = keyspace_name,
                        table_name = table_name,
                        line = line,
                        coulmns_metadata = columns_metadata,
                        columns_helper = columns_helper,
                        string_formats = string_formats)
    
    log.debug(insert)

    return batch.add(SimpleStatement(insert))
